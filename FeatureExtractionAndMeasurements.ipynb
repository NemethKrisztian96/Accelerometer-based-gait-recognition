{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FeatureExtractionAndMeasurements.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "tCX7JNbEhMdM",
        "BdmtYIH19C1j",
        "t2Um0p3rRQZn",
        "P1UpH0Z2RluD",
        "lCxdNz2qRmAn",
        "yLr9s84LRmMF"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NemethKrisztian96/Accelerometer-based-gait-recognition/blob/master/FeatureExtractionAndMeasurements.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsT6aP7SHZ6P",
        "colab_type": "text"
      },
      "source": [
        "Mount Google Drive in order to use as dataset source"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lK1oBN8RHKAA",
        "colab_type": "code",
        "outputId": "ac3f79f0-ccac-4757-e9b5-e71f24d00058",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdw9NkjAHgwb",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1OEDQQFHg6q",
        "colab_type": "code",
        "outputId": "80c2f6ad-ecbd-4224-e527-6399b523d427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Input, Dense\n",
        "from keras.layers import Reshape\n",
        "from keras.models import Model\n",
        "from sklearn import preprocessing\n",
        "from sklearn.decomposition import PCA, KernelPCA, SparsePCA\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from keras.utils import plot_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deloJOMBHwyp",
        "colab_type": "text"
      },
      "source": [
        "Settings and global attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P06xX_i5Hw5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Random states for reproducibility\n",
        "RANDOM_STATE = np.random.seed(0)\n",
        "\n",
        "# input frame size\n",
        "FRAME_SIZE = 128\n",
        "\n",
        "SESSION0 = 22\n",
        "SESSION1 = 153\n",
        "SESSION2 = 153\n",
        "SESSIONS = ['session_0/', 'session_1/', 'session_2/']\n",
        "\n",
        "# change these to the according paths\n",
        "FILES_PATH = '/content/drive/My Drive/Colab Notebooks/zju-gaitacc/'\n",
        "# FILES_PATH = '../../GaitBiometricsData/zju-gaitacc/zju-gaitacc/'\n",
        "FEATURES_DIR = '/content/drive/My Drive/Colab Notebooks/zju-gaitacc/Features/'\n",
        "# FEATURES_DIR = './Features/'\n",
        "\n",
        "# manual features\n",
        "# change this according to the file that has to be used for classification\n",
        "FEATURE_FILE = 'gaitacc128_session0.csv'\n",
        "# FEATURE_FILE = 'gaitacc128_session1.csv'\n",
        "# FEATURE_FILE = 'gaitacc128_session2.csv'\n",
        "\n",
        "# automatic features\n",
        "# change this according to the encoded session that has to be classified\n",
        "ENCODED_FILE = \"session_0.csv\"\n",
        "# ENCODED_FILE = \"session_1.csv\"\n",
        "# ENCODED_FILE = \"session_2.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKqPHzY8IKg9",
        "colab_type": "text"
      },
      "source": [
        "##Utility functions for different tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpV8gqIcIeOp",
        "colab_type": "text"
      },
      "source": [
        "For loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7C3s6qGIRjr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_session_files_list (session_number):\n",
        "    \"\"\"Loads a list with the files that have to be loaded\"\"\"\n",
        "    \n",
        "    users = []\n",
        "    for i in range(1, session_number + 1):\n",
        "        if i < 10:\n",
        "            for j in range(1, 7):\n",
        "                users.append(\"subj_00\" + str(i) + '/rec_' + str(j) + '/3.txt')\n",
        "        elif i < 100:\n",
        "            for j in range(1, 7):\n",
        "                users.append(\"subj_0\" + str(i) + '/rec_' + str(j) + '/3.txt')\n",
        "        else:\n",
        "            for j in range(1, 7):\n",
        "                users.append(\"subj_\" + str(i) + '/rec_' + str(j) + '/3.txt')\n",
        "    return users\n",
        "\n",
        "\n",
        "def load_dataset (path, files_list, session_index):\n",
        "    \"\"\"Loads the a session of the dataset from the given path and returns the \n",
        "    data in a (samples, frame_size=128, 3) shape numpy array\"\"\"\n",
        "    \n",
        "    print(\"Loading...\")\n",
        "    data = load_file(path + SESSIONS[session_index] + files_list[0])\n",
        "    labels = [files_list[0][5:8]] * len(data)\n",
        "    for name in files_list[1:]:\n",
        "        print(name)\n",
        "        loaded = load_file(path + SESSIONS[session_index] + name)\n",
        "        data = np.vstack((data, loaded))\n",
        "        labels += [name[5:8]] * len(loaded)\n",
        "    print(\"Loaded shape:\", data.shape)\n",
        "    print(\"Labels:\", len(labels))\n",
        "    return data, labels\n",
        "\n",
        "\n",
        "def load_file (file):\n",
        "    \"\"\"Loads the contents of one given file\"\"\"\n",
        "    \n",
        "    # files contain data for each axis on separate rows\n",
        "    with open(file) as f:\n",
        "        axis_x = f.readline()\n",
        "        axis_y = f.readline()\n",
        "        axis_z = f.readline()\n",
        "        axis_x = axis_x.strip('\\n').split(',')\n",
        "        axis_y = axis_y.strip('\\n').split(',')\n",
        "        axis_z = axis_z.strip('\\n').split(',')\n",
        "\n",
        "        if len(axis_x) != len(axis_y) and len(axis_x) != len(axis_z):\n",
        "            raise Exception(\"Corrupted file: \" + file)\n",
        "\n",
        "        counter = 0\n",
        "        # remove the last step if it is < 128 data points long\n",
        "        length = len(axis_x) - (len(axis_x) % 128)\n",
        "        arr = np.empty(shape=(length // 128, 128, 3))\n",
        "        for i in range(length):\n",
        "            sample = i // 128\n",
        "            arr[sample][counter][0] = float(axis_x[i])\n",
        "            arr[sample][counter][1] = float(axis_y[i])\n",
        "            arr[sample][counter][2] = float(axis_z[i])\n",
        "            counter += 1\n",
        "            if counter == 128:\n",
        "                counter = 0\n",
        "    return arr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuvknRb-KnOY",
        "colab_type": "text"
      },
      "source": [
        "Complementary functions for measuring classification performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkZbSNYyKnR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_measure (y_actual, y_pred):\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "        if y_actual[i] == y_pred[i]:\n",
        "            TP += 1\n",
        "        if y_pred[i] == 1 and y_actual[i] != y_pred[i]:\n",
        "            FP += 1\n",
        "        if y_actual[i] == y_pred[i] == 0:\n",
        "            TN += 1\n",
        "        if y_pred[i] == 0 and y_actual[i] != y_pred[i]:\n",
        "            FN += 1\n",
        "\n",
        "    return TP, FP, TN, FN\n",
        "\n",
        "\n",
        "def calc_sensitivity (y_test, y_pred):\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    # row = false positive, column = false negative\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "    for i in range(len(cm)):\n",
        "        for j in range(len(cm)):\n",
        "            if i == j:\n",
        "                TP += cm[i][i]\n",
        "            else:\n",
        "                FN += cm[j][i]\n",
        "    return TP / (TP + FN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5gPINktK7D8",
        "colab_type": "text"
      },
      "source": [
        "## Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlFVFU6fLFou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dense_autoencoder (activation_function='tanh'):\n",
        "    data0, ydata0 = load_dataset(FILES_PATH, load_session_files_list(SESSION0), 0)\n",
        "    data1, ydata1 = load_dataset(FILES_PATH, load_session_files_list(SESSION1), 1)\n",
        "    data2, ydata2 = load_dataset(FILES_PATH, load_session_files_list(SESSION2), 2)\n",
        "\n",
        "    data = np.concatenate((data0, data1, data2), axis=0)\n",
        "    ydata = np.concatenate((ydata0, ydata1, ydata2), axis=0)\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(data, ydata, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "    SEQUENCE_LENGTH, width, depth = 128, 3, 1\n",
        "\n",
        "    input_size = SEQUENCE_LENGTH * 3\n",
        "    input_frame = Input(shape=(SEQUENCE_LENGTH, 3))\n",
        "    # x = Dense(SEQUENCE_LENGTH, activation='linear', kernel_initializer=init.ones(), trainable=False)(input_frame)\n",
        "    x = Flatten()(input_frame)\n",
        "    x = Dense(input_size, activation=activation_function)(x)\n",
        "    encoded = Dense(320, activation=activation_function)(x)\n",
        "    encoded = Dense(256, activation=activation_function)(encoded)\n",
        "    encoded = Dense(192, activation=activation_function)(encoded)\n",
        "    encoded = Dense(128, activation=activation_function)(encoded)\n",
        "    encoded = Dense(96, activation=activation_function)(encoded)\n",
        "    encoded = Dense(64, activation=activation_function)(encoded)\n",
        "    encoded = Dense(48, activation=activation_function)(encoded)\n",
        "\n",
        "    y = Dense(22, activation=activation_function)(encoded)\n",
        "\n",
        "    decoded = Dense(48, activation=activation_function)(y)\n",
        "    decoded = Dense(64, activation=activation_function)(decoded)\n",
        "    decoded = Dense(96, activation=activation_function)(decoded)\n",
        "    decoded = Dense(128, activation=activation_function)(decoded)\n",
        "    decoded = Dense(192, activation=activation_function)(decoded)\n",
        "    decoded = Dense(256, activation=activation_function)(decoded)\n",
        "    decoded = Dense(320, activation=activation_function)(decoded)\n",
        "    z = Dense(input_size, activation=activation_function)(decoded)\n",
        "    z = Reshape(target_shape=(128, 3))(z)\n",
        "    autoencoder = Model(input_frame, z)\n",
        "\n",
        "    # encoder is the model of the autoencoder slice in the middle\n",
        "    encoder = Model(input_frame, y)\n",
        "\n",
        "    autoencoder.compile(optimizer='adadelta', loss='mse')  # reporting the loss\n",
        "    print(autoencoder.summary())\n",
        "    plot_model(autoencoder, show_shapes=True, to_file='/content/drive/My Drive/Colab Notebooks/encoder.png')\n",
        "    history = autoencoder.fit(X_train, X_train,\n",
        "                              epochs=20,\n",
        "                              batch_size=16,\n",
        "                              shuffle=True,\n",
        "                              validation_data=(X_test, X_test))\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    #plt.title('Veszteség')\n",
        "    plt.ylabel('Veszteség')\n",
        "    plt.xlabel('Korszak')\n",
        "    plt.xticks(np.arange(0, 20, 1.0))\n",
        "    plt.legend(['Tanítás', 'Validáció'], loc='upper right')\n",
        "    plt.savefig('/content/drive/My Drive/Colab Notebooks/autoencoder_loss', dpi=200)\n",
        "    plt.show()\n",
        "    return encoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_Jv-WEDMWXP",
        "colab_type": "text"
      },
      "source": [
        "Function for extracting features using the encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6mHkqtzMdz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features (encoder, session, session_idx):\n",
        "    print('Extracting features...')\n",
        "    # Load raw data and segment into frames\n",
        "\n",
        "    session_files = load_session_files_list(session)\n",
        "\n",
        "    data, ydata = load_dataset(FILES_PATH, session_files, session_idx)\n",
        "\n",
        "    print('data shape: ', str(data.shape))\n",
        "    # Extract features\n",
        "    encoded_frames = encoder.predict(data)\n",
        "    print(encoded_frames.shape)\n",
        "\n",
        "    # Normalize data\n",
        "    scaled_data = preprocessing.scale(encoded_frames)\n",
        "    # scaled_data = encoded_frames\n",
        "    num_features = encoded_frames.shape[1]\n",
        "\n",
        "    # Concatenate features(encoded_frames) with labels (ydata)\n",
        "    df1 = pd.DataFrame(data=scaled_data)\n",
        "    # df1 = df1.assign(pd.Series(ydata[1]).values)\n",
        "    df2 = pd.DataFrame(data=ydata, columns=[64])\n",
        "    df3 = pd.concat([df1, df2], axis=1)\n",
        "\n",
        "    # Save data into a CSV file\n",
        "    out_file = FEATURES_DIR + SESSIONS[session_idx][:-1] + \".csv\"\n",
        "    df3.to_csv(out_file, header=False, index=False)\n",
        "\n",
        "    print(\"Saved to: \" + out_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCX7JNbEhMdM",
        "colab_type": "text"
      },
      "source": [
        "##Extracting automatic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnwEvIexhPl5",
        "colab_type": "code",
        "outputId": "3d61fc46-c107-4b9f-a574-821dfede0e4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "encoder = dense_autoencoder()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "subj_153/rec_6/3.txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0704 10:43:13.988077 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0704 10:43:14.021299 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0704 10:43:14.042290 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded shape: (8897, 128, 3)\n",
            "Labels: 8897\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0704 10:43:14.230103 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 128, 3)            0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 320)               123200    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               82176     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 192)               49344     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 128)               24704     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 96)                12384     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 64)                6208      \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 48)                3120      \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 22)                1078      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 48)                1104      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                3136      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 96)                6240      \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 128)               12416     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 192)               24768     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 256)               49408     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 320)               82240     \n",
            "_________________________________________________________________\n",
            "dense_17 (Dense)             (None, 384)               123264    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 128, 3)            0         \n",
            "=================================================================\n",
            "Total params: 752,630\n",
            "Trainable params: 752,630\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0704 10:43:15.177799 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0704 10:43:15.185001 140250607974272 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 15464 samples, validate on 3866 samples\n",
            "Epoch 1/20\n",
            "15464/15464 [==============================] - 14s 933us/step - loss: 0.0646 - val_loss: 0.0487\n",
            "Epoch 2/20\n",
            "15464/15464 [==============================] - 10s 658us/step - loss: 0.0459 - val_loss: 0.0437\n",
            "Epoch 3/20\n",
            "15464/15464 [==============================] - 10s 649us/step - loss: 0.0427 - val_loss: 0.0417\n",
            "Epoch 4/20\n",
            "15464/15464 [==============================] - 10s 656us/step - loss: 0.0411 - val_loss: 0.0431\n",
            "Epoch 5/20\n",
            "15464/15464 [==============================] - 10s 654us/step - loss: 0.0398 - val_loss: 0.0399\n",
            "Epoch 6/20\n",
            "15464/15464 [==============================] - 10s 654us/step - loss: 0.0387 - val_loss: 0.0385\n",
            "Epoch 7/20\n",
            "15464/15464 [==============================] - 10s 659us/step - loss: 0.0378 - val_loss: 0.0388\n",
            "Epoch 8/20\n",
            "15464/15464 [==============================] - 10s 647us/step - loss: 0.0369 - val_loss: 0.0367\n",
            "Epoch 9/20\n",
            "15464/15464 [==============================] - 10s 649us/step - loss: 0.0363 - val_loss: 0.0361\n",
            "Epoch 10/20\n",
            "15464/15464 [==============================] - 10s 656us/step - loss: 0.0358 - val_loss: 0.0356\n",
            "Epoch 11/20\n",
            "15464/15464 [==============================] - 10s 653us/step - loss: 0.0353 - val_loss: 0.0353\n",
            "Epoch 12/20\n",
            "15464/15464 [==============================] - 10s 649us/step - loss: 0.0349 - val_loss: 0.0346\n",
            "Epoch 13/20\n",
            "15464/15464 [==============================] - 10s 647us/step - loss: 0.0345 - val_loss: 0.0346\n",
            "Epoch 14/20\n",
            "15464/15464 [==============================] - 10s 646us/step - loss: 0.0340 - val_loss: 0.0345\n",
            "Epoch 15/20\n",
            "15464/15464 [==============================] - 10s 645us/step - loss: 0.0337 - val_loss: 0.0335\n",
            "Epoch 16/20\n",
            "15464/15464 [==============================] - 10s 647us/step - loss: 0.0334 - val_loss: 0.0338\n",
            "Epoch 17/20\n",
            "15464/15464 [==============================] - 10s 655us/step - loss: 0.0332 - val_loss: 0.0337\n",
            "Epoch 18/20\n",
            "15464/15464 [==============================] - 10s 654us/step - loss: 0.0329 - val_loss: 0.0335\n",
            "Epoch 19/20\n",
            "15464/15464 [==============================] - 10s 648us/step - loss: 0.0327 - val_loss: 0.0330\n",
            "Epoch 20/20\n",
            "15464/15464 [==============================] - 10s 649us/step - loss: 0.0325 - val_loss: 0.0325\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFgskxhhjmsUCiTHGmGb5//yM5x+pUj8JAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGBsKa3KhVJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "extract_features(encoder, SESSION0, 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS972qHRKe7g",
        "colab_type": "text"
      },
      "source": [
        "Save/load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw6CDPsrKdwD",
        "colab_type": "code",
        "outputId": "b8a8d5f1-4891-4665-dd94-74b8de82740c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "MODEL_LOCATION = '/content/drive/My Drive/Colab Notebooks/'\n",
        "\n",
        "# save\n",
        "encoder.save(MODEL_LOCATION + 'dense_encoder.h5')\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# load\n",
        "from keras.models import load_model\n",
        "encoder = load_model(MODEL_LOCATION + 'dense_encoder.h5')\n",
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 128, 3)            0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 384)               0         \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 384)               147840    \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 320)               123200    \n",
            "_________________________________________________________________\n",
            "dense_69 (Dense)             (None, 256)               82176     \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 196)               50372     \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 128)               25216     \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 96)                12384     \n",
            "_________________________________________________________________\n",
            "dense_73 (Dense)             (None, 64)                6208      \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 48)                3120      \n",
            "_________________________________________________________________\n",
            "dense_75 (Dense)             (None, 22)                1078      \n",
            "=================================================================\n",
            "Total params: 451,594\n",
            "Trainable params: 451,594\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "  warnings.warn('No training configuration found in save file: '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRGuqpXGODWE",
        "colab_type": "text"
      },
      "source": [
        "## Classification using SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdmtYIH19C1j",
        "colab_type": "text"
      },
      "source": [
        "###Function definitions for classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "En9XfEpsOIff",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_manual_features (with_scaling=False):\n",
        "    file = FEATURES_DIR + FEATURE_FILE\n",
        "    csvdf = pd.read_csv(file, sep=',')\n",
        "    csvdf['userID'] = [int(value[1:]) for value in csvdf['userID']]\n",
        "    labels = csvdf.iloc[:, -1]\n",
        "    csvdf = csvdf.iloc[:, :-1]\n",
        "\n",
        "    # Test train split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(csvdf, labels, test_size=0.25)\n",
        "    \n",
        "    if with_scaling:\n",
        "        # Standard scaling\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.fit_transform(X_test)\n",
        "\n",
        "    # Create SVM classifier\n",
        "    classifier_svm_kernel = SVC(C=100.0, kernel='rbf', gamma='scale', tol=0.00001, decision_function_shape='ovo',\n",
        "                                verbose=True)\n",
        "    classifier_svm_kernel.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the result for test values\n",
        "    y_pred = classifier_svm_kernel.predict(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # print(accuracy_score(y_test, y_pred))\n",
        "    print(\"Sensitivity:\", calc_sensitivity(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTCSfn0wOQ25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def svm_autoencoder_features (with_scaling=False):\n",
        "    file = FEATURES_DIR + ENCODED_FILE\n",
        "    csvdf = pd.read_csv(file, sep=',')\n",
        "    labels = csvdf.iloc[:, -1]\n",
        "    csvdf = csvdf.iloc[:, :-1]\n",
        "\n",
        "    # Test train split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(csvdf, labels, test_size=0.25)\n",
        "\n",
        "    if with_scaling:\n",
        "        # Standard scaling\n",
        "        sc = StandardScaler()\n",
        "        X_train = sc.fit_transform(X_train)\n",
        "        X_test = sc.fit_transform(X_test)\n",
        "\n",
        "    # Create SVM classifier\n",
        "    classifier_svm_kernel = SVC(C=100.0, kernel='rbf', gamma='scale', tol=0.00001, decision_function_shape='ovo',\n",
        "                                verbose=True)\n",
        "    classifier_svm_kernel.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the result for test values\n",
        "    y_pred = classifier_svm_kernel.predict(X_test)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(cm)\n",
        "\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    # print(accuracy_score(y_test, y_pred))\n",
        "    print(\"Sensitivity:\", calc_sensitivity(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pkPapgZRIys",
        "colab_type": "text"
      },
      "source": [
        "###Test cases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Um0p3rRQZn",
        "colab_type": "text"
      },
      "source": [
        "####1. Manual features from the FeatureExtractorLibrary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30-2__KsRMJV",
        "colab_type": "code",
        "outputId": "f5d36efe-a3c0-4deb-9bc5-493c1dc28c6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "FEATURE_FILE = 'gaitacc128_session0.csv'\n",
        "svm_manual_features(True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM][[20  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0]\n",
            " [ 0 17  0  2  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  1]\n",
            " [ 0  0 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0]\n",
            " [ 1  0  0 13  0  0  0  0  0  1  2  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  1  0  0 16  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  1  0  0  1  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0 12  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  1  8  2  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 1  0  0  0  0  0  0  0  0  0  1 13  2  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  0  0  0  0  0  1  0 13  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  1  2  0  0  0  0  0  0  0  0  0  9  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 13  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0 24  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0 17  1  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0 22  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.91      0.91        22\n",
            "           2       0.85      0.77      0.81        22\n",
            "           3       0.89      0.89      0.89        19\n",
            "           4       0.72      0.72      0.72        18\n",
            "           5       1.00      1.00      1.00        15\n",
            "           6       0.89      0.84      0.86        19\n",
            "           7       0.93      0.81      0.87        16\n",
            "           8       0.93      1.00      0.96        13\n",
            "           9       0.86      0.86      0.86        14\n",
            "          10       0.67      0.67      0.67        12\n",
            "          11       0.63      1.00      0.77        12\n",
            "          12       1.00      0.76      0.87        17\n",
            "          13       0.76      0.87      0.81        15\n",
            "          14       1.00      0.60      0.75        15\n",
            "          15       0.72      0.93      0.81        14\n",
            "          16       0.88      1.00      0.94        15\n",
            "          17       1.00      0.96      0.98        24\n",
            "          18       0.96      0.96      0.96        25\n",
            "          19       0.94      0.89      0.92        19\n",
            "          20       0.83      1.00      0.91        10\n",
            "          21       1.00      0.92      0.96        24\n",
            "          22       0.95      1.00      0.97        19\n",
            "\n",
            "    accuracy                           0.88       379\n",
            "   macro avg       0.88      0.88      0.87       379\n",
            "weighted avg       0.89      0.88      0.88       379\n",
            "\n",
            "Sensitivity: 0.8812664907651715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCxdNz2qRmAn",
        "colab_type": "text"
      },
      "source": [
        "####2. SVM on automatic features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_988MHtRmFx",
        "colab_type": "code",
        "outputId": "ef073deb-4f6f-4273-8312-4e31a685678d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "ENCODED_FILE = \"session_0.csv\"\n",
        "svm_autoencoder_features()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LibSVM][[19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 19  0  0  0  0  0  0  1  0  0  0  2  0  0  0  0  2  0  0  0  0]\n",
            " [ 0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
            " [ 0  1  0 14  0  0  0  0  1  0  2  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 12  2  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  5  1  2  0  1  0  1  1  0  0  0  2  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  1  1  0  9  0  1  0  0  1  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  1  0  0  0  0  0  5  0  1  0  0  0  0  0  0  2  0  0  0  2]\n",
            " [ 0  1  0  0  0  0  0  1  0  7  0  0  1  0  1  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  1  0  1  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  2  0  0  0  0  0  2  0  2  0  0  8  1  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  2  0  2  0  0  1  0  0  0  1  6  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 17  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0]\n",
            " [ 0  1  3  0  0  0  0  0  1  0  0  0  1  0  0  0  0 19  0  0  0  0]\n",
            " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0]\n",
            " [ 0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0 16]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00        19\n",
            "           2       0.68      0.79      0.73        24\n",
            "           3       0.65      0.92      0.76        12\n",
            "           4       0.82      0.74      0.78        19\n",
            "           5       0.92      0.71      0.80        17\n",
            "           6       0.42      0.38      0.40        13\n",
            "           7       0.92      1.00      0.96        11\n",
            "           8       0.56      0.64      0.60        14\n",
            "           9       0.50      0.38      0.43        13\n",
            "          10       0.64      0.64      0.64        11\n",
            "          11       0.80      1.00      0.89        12\n",
            "          12       0.91      0.83      0.87        12\n",
            "          13       0.53      0.53      0.53        15\n",
            "          14       0.75      0.46      0.57        13\n",
            "          15       0.77      1.00      0.87        10\n",
            "          16       1.00      1.00      1.00        17\n",
            "          17       0.91      0.95      0.93        22\n",
            "          18       0.83      0.76      0.79        25\n",
            "          19       0.95      0.91      0.93        22\n",
            "          20       1.00      1.00      1.00        10\n",
            "          21       1.00      1.00      1.00        16\n",
            "          22       0.89      0.89      0.89        18\n",
            "\n",
            "    accuracy                           0.80       345\n",
            "   macro avg       0.79      0.80      0.79       345\n",
            "weighted avg       0.81      0.80      0.80       345\n",
            "\n",
            "Sensitivity: 0.8028985507246377\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}